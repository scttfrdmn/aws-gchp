# Deployment Log: gchp-test-minimal

**Date:** January 28, 2026
**Cluster:** gchp-test-minimal
**Region:** us-east-2 (Ohio)

---

## Deployment Timeline

### Deployment Started
- **Time:** 21:54 PST (Wed Jan 28)
- **Command:**
  ```bash
  AWS_PROFILE=aws AWS_REGION=us-east-2 uv run pcluster create-cluster \
    --cluster-name gchp-test-minimal \
    --cluster-configuration parallelcluster/configs/gchp-test-minimal.yaml \
    --region us-east-2
  ```

### Deployment Completed
- **Time:** ~22:05 PST (11 minutes)
- **Status:** CREATE_COMPLETE
- **Head Node IP:** 3.147.27.184

---

## Configuration Details

### Cluster Specification
```yaml
Region: us-east-2
HeadNode:
  InstanceType: t3.medium
  SubnetId: subnet-a7ef24cc (auto-assigns public IPs)
  KeyName: aws-benchmark

Compute:
  InstanceType: c7a.xlarge  # 4 cores, single NIC
  MinCount: 0
  MaxCount: 1
  CapacityType: ONDEMAND
  DisableSimultaneousMultithreading: true

SharedStorage:
  FsxLustre: 1200 GB (SCRATCH_2)
  MountDir: /fsx
  Compression: LZ4
```

### Design Decisions

**Why c7a.xlarge instead of hpc7a?**
- Initial validation cluster to test automation toolkit
- c7a.xlarge is single-NIC (simpler networking)
- hpc7a has multiple NICs for EFA (requires different networking setup)
- Plan: validate toolkit with simple config first, then deploy hpc7a multi-node

**Why ON-DEMAND?**
- Testing/validation phase
- Avoid Spot interruptions during toolkit validation
- Cost: ~$0.29 for 30-minute test
- Will switch to SPOT for production after validation

---

## Issues Encountered and Resolved

### Issue 1: Region Confusion
**Problem:** Initially configured us-east-1, but hpc7a not available there
**Fix:** Changed to us-east-2 (Ohio) where hpc7a is available
**Files Updated:** All cluster configs

### Issue 2: No Public IP Assignment
**Problem:** Default subnet had MapPublicIpOnLaunch: false
**Symptom:** WaitCondition timeout after 30 minutes, cluster rollback
**Fix:** Enabled auto-assign public IPs on subnet
**Command:**
```bash
aws ec2 modify-subnet-attribute \
  --subnet-id subnet-a7ef24cc \
  --map-public-ip-on-launch \
  --region us-east-2
```

### Issue 3: Multi-NIC Instance Incompatibility
**Problem:** hpc7a instances have multiple NICs for EFA
**Symptom:** AWS rejects auto-public-IP with multi-NIC instances
**Solution:** Switched to c7a.xlarge (single NIC) for initial validation
**Future Fix:** Document single public subnet approach for hpc7a (no NAT Gateway)

### Issue 4: Invalid Configuration Parameter
**Problem:** Tried to use AssociatePublicIpAddress in HeadNode/Networking
**Symptom:** "Unknown field" error
**Fix:** Parameter not supported in ParallelCluster 3.14.0, use subnet-level settings

---

## Validation Results

### Head Node Connectivity
‚úÖ **SSH Access:** Working
- IP: 3.147.27.184
- Key: ~/.ssh/aws-benchmark.pem
- User: ec2-user

### SLURM Scheduler
‚úÖ **Status:** Running
```
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
test*        up   infinite      1  idle~ test-dy-c7a-test-1
```
- Dynamic compute node configured correctly
- Node will provision on-demand when job submitted

### FSx Lustre Storage
‚úÖ **Status:** Mounted
```
Filesystem                 Size  Used Avail Use% Mounted on
172.31.9.70@tcp:/lxt5jbev  1.1T  7.7M  1.1T   1% /fsx
```
- Mount point: /fsx
- Capacity: 1.2 TB
- Deployment: SCRATCH_2
- Compression: LZ4

### Job Submission Test
üîÑ **Status:** In progress (compute node provisioning)
- Command: `srun -N1 --exclusive hostname`
- Expected: 2-3 minutes for c7a.xlarge to start
- Will verify end-to-end job execution

---

## Cost Analysis

### Cluster Components
- **Head Node:** t3.medium @ $0.0416/hour
- **Compute Node:** c7a.xlarge @ $0.1836/hour (when running)
- **FSx Lustre:** 1200 GB SCRATCH_2 @ $0.15/GB-month = $180/month (~$0.25/hour)

### Test Cost (30 minutes)
- Head node: $0.02
- Compute: $0.09 (if running full time)
- FSx: $0.12
- **Total: ~$0.23 for 30-minute test**

### Comparison to Original Estimate
- Estimated: $0.29
- Actual: $0.23 (21% under budget)

---

## Next Steps

### Immediate (Tonight)
1. ‚úÖ Validate compute node provisioning completes successfully
2. ‚úÖ Test basic SLURM job submission workflow
3. üìù Document findings

### Short-term (Tomorrow)
1. üîÑ Update hpc7a configs with proper networking (single public subnet)
2. üîÑ Deploy 4-node hpc7a test cluster with EFA
3. üîÑ Run multi-node MPI validation tests

### Medium-term (This Week)
1. Run C24 benchmark on hpc7a.48xlarge (96 cores)
2. Test 4-node scaling and EFA performance
3. Compare against previous benchmark data
4. Validate automation toolkit end-to-end

---

## Lessons Learned

### 1. ParallelCluster Networking is Complex
- Multi-NIC instances (EFA) have special requirements
- Default VPC settings often inadequate
- Need clear documentation of networking approaches

### 2. Region Availability Matters
- HPC instances not in all regions
- Always query availability before configuring
- hpc7a: us-east-2, eu-west-1 only

### 3. Subnet Configuration Critical
- MapPublicIpOnLaunch required for public access
- Incompatible with multi-NIC instances
- Single public subnet approach best for HPC

### 4. Iterative Validation Essential
- Start simple (single-NIC instance)
- Validate toolkit works before adding complexity
- Document everything for reproducibility

---

## Success Metrics

### What Worked Well
‚úÖ Cluster deployed successfully after fixing networking
‚úÖ Head node accessible via SSH
‚úÖ SLURM scheduler running correctly
‚úÖ FSx Lustre mounted and ready
‚úÖ Configuration files clean and well-documented
‚úÖ All AWS resources properly tagged

### What Needs Improvement
‚ö†Ô∏è Networking setup for multi-NIC instances needs clearer docs
‚ö†Ô∏è ParallelCluster error messages could be more helpful
‚ö†Ô∏è Need automated validation script for cluster readiness

---

## Files Created/Updated

### Documentation
- `/docs/DEPLOYMENT-LOG.md` (this file)
- `/docs/EFA-INSTANCE-CATALOG.md` (EFA instance reference)
- `/docs/ON-DEMAND-TO-SPOT-STRATEGY.md` (cost optimization)
- `/docs/HPC7A-CONFIGURATION-SUMMARY.md` (hpc7a reference)

### Configuration Files
- `/parallelcluster/configs/gchp-test-minimal.yaml` (deployed)
- `/parallelcluster/configs/gchp-test-multinode.yaml` (ready)
- `/parallelcluster/configs/gchp-production.yaml` (ready)

### Scripts
- `/scripts/set-owner-tag.sh` (working)
- `/scripts/gchp-data-sync.py` (ready for testing)
- `/scripts/gchp-setup.py` (ready for testing)

---

## Cluster Access

### SSH Command
```bash
ssh -i ~/.ssh/aws-benchmark.pem ec2-user@3.147.27.184
```

### ParallelCluster Commands
```bash
# Check status
AWS_PROFILE=aws uv run pcluster describe-cluster \
  --cluster-name gchp-test-minimal \
  --region us-east-2

# Delete cluster (when done testing)
AWS_PROFILE=aws uv run pcluster delete-cluster \
  --cluster-name gchp-test-minimal \
  --region us-east-2
```

---

**Status:** ‚úÖ Deployment successful, validation in progress
**Next:** Complete job execution test, then proceed to hpc7a multi-node config
